---
layout: post
title: "Shifted Grad-Transformer Are Efficient Signal Classifier "
date: 2021-12-28 09:03:21 UTC+8
tags: wfnian
excerpt: "article. | research direction: computer science(signal process)"
css: ["whisper.css", "xue.css"]
---

<p style="text-align:center">wfnian*☨, _, *, project lead, Beijng University, Beijing University of Chemical Technology.  Defense-linked research project.</p>

<p class="s-title">Abstract</p>

<p class="s-content">We proposed a faster, higher accuracy framework for most of signal-liked One dimensional data, this work  discard conditional 小波变换，傅里叶变换，频谱图变换等方法，从离散一维信号的一阶导数的基本思想突破，合并了高阶导数，同时加入了多尺度信息。实验结果与最新的LSTM，Text-CNN， Google的mlp-mixer，等诸多方法做比较，实验结果表明，在我们的256分类数据集◈上最高准确率为70%，同时我们将我们的方法迁移到医学心电信号分类中(ECG classification Mit-Bih)，相比于文献[1]的95.7%，我们的方法能达到98.7，提升了三个点，we also 尝试了高光谱像素分类，雷达极化数据分类，实验结果表明我们的方法能以很快的速度达到很好的准确率（分别是96.84%，85%，），我们也尝试了自然语言处理的语音信号分类，很遗憾由于语音信号不具有连续性，我们的方法并不适用于不可导的一维数据。Training code and pretrained models are available at <a href="https://github.com/wfnian/signal_classification">https://github.com/wfnian/signal_classification.</a></p>

<div class="s-index">01 introduction</div>
<br>
<div class="s-index">3.3 Implementation Details</div>
<p class="s-content">We use the PyTorch framework to implement our proposed Shifted Grad-Transformer model, for army data of the ship, we used GTX 3060 12GB and set batch size=10240, for the medical data of ECG, we set batch size=128, we found a smaller batch size sometimes works better, for data of 高光谱数据, Pavia数据采用随机取样10%, 103通道, 训练时候设置learning rate 为0.001，对于极化雷达PolSar-Flevoland数据，随机取样为10%，
</p>

<div class="s-index">Conclusion</div>
<p class="s-content">Our model is a universal framework, it works on 连续的、一维的数据分类，在速度和精度上都可以达到相应的state-of-art work. 我们的方法在军事一维连续数据◈，医学一维连续数据，遥感一维连续数据，高光谱的一维连续数据，等各数据集上表现十分good。虽然我们的模型普遍适用于一位连续数据，但是对于在数学意义上不连续不可导的类似语音的数据，我们的模型也具有局限性。</p>

<br>
<p style="text-align:left;font-size:20px;font-weight:bold">Reference</p>
<p style="text-align:left;font-size:16px;">[1]</p>
<hr>
◈ 涉密

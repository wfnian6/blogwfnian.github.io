---
layout: post
title: "Shifted Grad-Transformer Are Efficient Signal Classifier(待定)"
date: 2022-01-01 12:18:55 UTC+8
tags: wfnian
excerpt: "preprint. | research direction: computer science"
css: ["whisper.css", "xue.css"]
---

<p style="text-align:center">wfnian*☨, _, *, project lead, Beijng University, Beijing University of Chemical Technology.  Defense-linked research project.</p>

<p class="s-title">Abstract</p>

<p class="s-content">We propose a faster, higher accuracy framework for most of signal-liked One dimensional data, this work  discard conditional 小波变换，傅里叶变换，频谱图变换等方法，从离散一维信号的一阶导数的基本思想突破，合并了高阶导数，同时加入了多尺度信息。实验结果与LSTM，Text-CNN， Google的mlp-mixer，等诸多方法做比较，实验结果表明，在我们的256分类数据集◈上最高准确率为70%，同时我们将我们的方法迁移到医学心电信号分类中(ECG classification Mit-Bih)，相比于文献[1]的95.7%，我们的方法能达到98.7，提升了三个点，we also 尝试了高光谱像素分类，雷达极化数据分类，实验结果表明我们的方法能以很快的速度达到很好的准确率（分别是97.11%，85%，），在磁化数据，医学心电图数据，高光谱图像数据，极化雷达sar数据上的效果证明了我们的方法是通用型方法，我们也尝试了自然语言处理的语音信号分类，很遗憾由于语音信号不具有连续性，我们的方法并不适用于不可导的一维数据。This seemingly discouraging outcome may be expected. But our model works well with one-dimensional continuous data. Our Training code and data are available at <a href="https://github.com/wfnian/signal_classification" style="color:blue;text-decoration: underline;">https://github.com/wfnian/signal_classification.</a></p>

<div class="s-index">01 introduction</div>
<p class="s-content">在处理一维时序信号时候，小波变换，傅里叶变化，频谱图往往是最通用的方法，将一维时序信号转为三位图像然后利用传统的卷积网络进行下游任务处理。例如在生成频谱图的时候，往往将一维数据变换为二维数据的时候，产生了大量的冗余信息，同时消耗了更多的计算资源来追求下游任务更高的准确率，我们的方法就不一样了，very nb，super nb，terribly nb，直接抛弃现有的所有，直接将一维数据塞进网络，也可以达到大部分以小波变换，傅里叶变换，频谱变换处理后的精度以及更高。而且在速度，参数量方面Beyond all methods.同时我们的shift-Grad可以作为一个单独的插件，后面接任意的下游任务网络.
In this paper, because of the Transformer is notable for use of attention to model long-range dependencies in the data. We use improved vision transformer for classification.</p>
<br>
<div class="s-index">3.3 Implementation Details</div>
<p class="s-content">We use the PyTorch framework to implement our proposed Shifted Grad-Transformer model, for army data of the ship, we used GTX 3060 12GB and set batch size=10240, for the medical data of ECG, we set batch size=128, we found a smaller batch size sometimes works better, for data of 高光谱数据, Pavia数据采用随机取样10%, 103通道, 训练时候设置learning rate 为0.001，对于极化雷达PolSar-Flevoland数据，随机取样为10%，
</p>

<div class="s-index">Conclusion</div>
<p class="s-content">Our model is a universal framework, it works on 连续的、一维的数据分类，在速度和精度上都可以达到相应的state-of-art work. 我们的方法在军事一维连续数据◈，医学一维连续数据，遥感一维连续数据，高光谱的一维连续数据，等各数据集上表现十分good。虽然我们的模型普遍适用于一位连续数据，但是对于在数学意义上不连续不可导的类似语音的数据，我们的模型也具有局限性。</p>

<br>
<p style="text-align:left;font-size:20px;font-weight:bold">Reference</p>
<p style="text-align:left;font-size:16px;">[1]</p>
<p style="text-align:left;font-size:16px;">[2]Dosovitskiy, A., “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”, <i>arXiv e-prints</i>, 2020.</p>
<hr>
◈ 涉密
<hr>
第一篇： <a href="{{site.baseurl}}/workspace/paper/2022-01-01-第IIII篇论文.html" style="color:blue;text-decoration: underline;">Combined with material corrosion life prediction of Transformer(待定)[交叉学科]</a>
<br>
第二篇： <a href="{{site.baseurl}}/workspace/paper/2022-01-01-第IIII篇论文.html" style="color:blue;text-decoration: underline;">A new evaluation criterion for material corrosion(待定)[交叉学科]</a>
